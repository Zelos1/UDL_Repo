{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "080fe6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: torch.Size([60000, 1, 28, 28])\n",
      "60000 train samples, before reduction\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from load_data import load_mnist\n",
    "from util import *\n",
    "import copy\n",
    "\n",
    "import time\n",
    "import math\n",
    "np.random.seed(43)\n",
    "\n",
    "x_train_new, y_train_new, X_p, y_p, x_val, y_val, x_test, y_test = load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9cf486e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 30\n",
    "acquired_points = 10\n",
    "num_classes = 10\n",
    "acquisition_times = 100\n",
    "device = torch.device(\"mps\") if torch.mps.is_available() else \"cpu\"\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else device\n",
    "x_train_new = x_train_new.to(dtype=torch.float32).to(device)\n",
    "y_train_new = y_train_new.to(dtype=torch.float32).to(device)\n",
    "X_p = X_p.to(dtype=torch.float32)\n",
    "y_p = y_p.to(dtype=torch.float32)\n",
    "x_val = x_val.to(device)\n",
    "y_val = y_val.to(device)\n",
    "x_test = x_test.to(device)\n",
    "y_test = y_test.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf8cda3",
   "metadata": {},
   "source": [
    "# VI utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0490db8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is actually treated as the std\n",
    "weights_prior_std = 0.01\n",
    "# This implies that the covariance matrix of each W_i is diag(weights_prior_var^2), ..., weights_prior_var^2)\n",
    "sigma_1_inv = torch.diag(torch.ones(128) * (1.0 / (weights_prior_std ** 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5a6ab323",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchicalRegressor(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=4), # -3 width/height\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, kernel_size=4), # -3 width/height\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2), # /2 width/height,\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(32 * 11 * 11, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        nn.init.normal_(self.fc2.weight, mean=0.0, std=weights_prior_std)\n",
    "        nn.init.zeros_(self.fc2.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d4d0a4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pred_cov(sigma_2, model, x, blocks_of_cov_post):\n",
    "    model.eval()\n",
    "    y_ast = model(x)\n",
    "    V_pred = torch.einsum('bd,kde,be->kb', y_ast, blocks_of_cov_post, y_ast).T\n",
    "    idx = torch.arange(V_pred.shape[0] * sigma_2.shape[0], device=sigma_2.device) % sigma_2.shape[0]\n",
    "    sigma_2_rep = sigma_2[idx]\n",
    "    return V_pred + torch.reshape(sigma_2_rep, (V_pred.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fe4bbad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pred_mean(model, x, posterior_mean):\n",
    "    model.eval()\n",
    "    y_ast = model(x)\n",
    "    M_pred = y_ast @ posterior_mean.reshape((posterior_mean.shape[0], posterior_mean.shape[1])).T\n",
    "    return M_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c752c599",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianLastLayerModel(nn.Module):\n",
    "    def __init__(self, compute_posterior_mean, compute_posterior_cov, feat_extractor, sigma2, output_dim=10, feature_dim=128, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.feature_extractor = feat_extractor\n",
    "\n",
    "        self.feature_dim = feature_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.M_ast = torch.zeros((output_dim, feature_dim), device=device)\n",
    "        diag = torch.eye(feature_dim, device=device)\n",
    "        idx = torch.arange(output_dim * diag.shape[0], device=diag.device) % diag.shape[0]\n",
    "        \n",
    "        self.V_ast = (weights_prior_std ** 2) * diag[idx].reshape(output_dim, feature_dim, feature_dim)\n",
    "        self.compute_posterior_mean = compute_posterior_mean\n",
    "        self.compute_posterior_cov = compute_posterior_cov\n",
    "        self.sigma2 = sigma2.to(device=device)\n",
    "\n",
    "    def fit_posterior(self, X, Y):\n",
    "        self.M_ast = self.compute_posterior_mean(1, self.feature_extractor, X, Y, self.sigma2).reshape((self.output_dim, self.feature_dim))\n",
    "        v_ast_blocks = self.compute_posterior_cov(1, self.feature_extractor, X, Y, self.sigma2)\n",
    "        if type(v_ast_blocks) == list:\n",
    "          self.V_ast = torch.stack(v_ast_blocks)\n",
    "        else: # is already stacked tensor\n",
    "          self.V_ast = v_ast_blocks\n",
    "\n",
    "    def sample_y_pred(self, x):\n",
    "        \"\"\"\n",
    "        Draw y ~ N(M_pred, V_pred) V_pred is diagonal following the proof from the paper. This expects to have M_ast, V_ast already computed for the given X, Y.\n",
    "        \"\"\"\n",
    "        M_hat = compute_pred_mean(self.feature_extractor, x, self.M_ast)\n",
    "        V_hat = compute_pred_cov(self.sigma2, self.feature_extractor, x, self.V_ast)\n",
    "        epsilon = torch.normal(torch.zeros((5, V_hat.shape[0], V_hat.shape[1])), torch.ones((5, V_hat.shape[0], V_hat.shape[1]))).to(device)\n",
    "        V_hat = torch.unsqueeze(torch.sqrt(V_hat), 0)\n",
    "        idx = torch.arange(5 * V_hat.shape[0], device=V_hat.device) % V_hat.shape[0]\n",
    "        y_hat = M_hat + torch.sum(V_hat[idx] * epsilon, axis=0)\n",
    "        return y_hat\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        sample = self.sample_y_pred(x)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059bf6ff",
   "metadata": {},
   "source": [
    "# Variational Inference Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "19f38ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_mean_mfvi_diag(T, model, X, Y, sigma_2):\n",
    "    model.eval()\n",
    "    y_pred = model(X)\n",
    "    p_t_p = y_pred.T @ y_pred\n",
    "    p_t_y = y_pred.T @ Y\n",
    "    m_ast = []\n",
    "\n",
    "    for i in range(10):\n",
    "        reg = (sigma_2[i] / (weights_prior_std ** 2)) * torch.eye(y_pred.shape[1], device=device)\n",
    "        m_i_ast = torch.linalg.solve(reg + p_t_p, p_t_y[:,i:i+1])\n",
    "        m_ast.append(m_i_ast)\n",
    "    M_ast = torch.stack(m_ast)\n",
    "    return M_ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b5d52a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_mean_mfvi_full(T, model, X, Y, sigma_2):\n",
    "    model.eval()\n",
    "    y_pred = model(X)\n",
    "\n",
    "    n, K = y_pred.shape\n",
    "    A = y_pred.T @ y_pred\n",
    "    C = y_pred @ Y\n",
    "    b = sigma_2 / (weights_prior_std ** 2)\n",
    "\n",
    "    M_cols = []\n",
    "    for i in range(Y.shape[1]):\n",
    "        Ai = A + b[i] * torch.eye(K, device=device)\n",
    "        rhs_i = C[:, i:i+1]\n",
    "        sol_i = torch.linalg.solve(Ai, rhs_i)\n",
    "        M_cols.append(sol_i)\n",
    "\n",
    "    M_star = torch.concat(M_cols, axis=1)\n",
    "    return M_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f8bb031a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_cov_mfvi_full(T, model, X, Y, sigma_2):\n",
    "    model.eval()\n",
    "    y_pred = model(X)\n",
    "\n",
    "    p_p_t = y_pred.T @ y_pred\n",
    "\n",
    "    V_I_r = [] # only keep the block matrices on the diagonal. Rest is 0. Do not explicitly turn it into matrix\n",
    "    for i in range(sigma_2.shape[0]):\n",
    "        A_i = p_p_t * (1 / sigma_2[i]) + (1 / weights_prior_std ** 2) * torch.eye(p_p_t.shape[0], device=device)\n",
    "        V_I_r.append(torch.linalg.inv(A_i))\n",
    "    return V_I_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4e7888fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_cov_mfvi_diag(T, model, X, Y, sigma_2):\n",
    "    model.eval()\n",
    "    y_pred = model(X)\n",
    "    phi_r = torch.sum(y_pred ** 2, axis=0)\n",
    "\n",
    "    denom = phi_r.unsqueeze(0) / (sigma_2 ** 2).unsqueeze(1) + 1.0 / (weights_prior_std ** 2)\n",
    "\n",
    "    V_ast = 1.0 / denom\n",
    "    V_ast = torch.diag_embed(V_ast)\n",
    "    return V_ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "414cef28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_cov_ai(T, model, X, Y, sigma_2):\n",
    "    model.eval()\n",
    "    y_pred = model(X)\n",
    "\n",
    "    sigmas_prime = []\n",
    "    for i in range(num_classes):\n",
    "        sigmas_prime_i = torch.linalg.inv((1 / (weights_prior_std ** 2)) * torch.eye(y_pred.shape[1], device=device) + (1 / sigma_2[i]) * (y_pred.T @ y_pred))\n",
    "        sigmas_prime.append(sigmas_prime_i)\n",
    "    return torch.stack(sigmas_prime, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "37ffe1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_mean_ai(T, model, X, Y, sigma_2):\n",
    "    model.eval()\n",
    "    y_pred = model(X)\n",
    "    sigmas_prime = posterior_cov_ai(T, model, X, Y, sigma_2)\n",
    "    PhiY = y_pred.T @ Y\n",
    "    scale = 1 / sigma_2\n",
    "    phiY_scaled = PhiY * torch.unsqueeze(scale, dim=0)\n",
    "    mu_prime = torch.einsum('mdk,km->md', sigmas_prime, phiY_scaled)\n",
    "\n",
    "    return mu_prime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5602b688",
   "metadata": {},
   "source": [
    "# Pipeline VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9d34dc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "vi_acq_functions = {\"analytical_inference\": (posterior_mean_ai, posterior_cov_ai), \"mfvi_full\": (posterior_mean_mfvi_full, posterior_cov_mfvi_full), \"mfvi_diag\": (posterior_mean_mfvi_diag, posterior_cov_mfvi_diag)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "01283e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_loss(y_true, y_pred):\n",
    "    mse = torch.mean(torch.square(y_true - y_pred))\n",
    "    return torch.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a9744468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gc\n",
    "\n",
    "def find_best_decay_local_cnn(x_train, y_train):\n",
    "    weight_decays = [0, 1e-6, 5e-6, 1e-5, 1e-4]\n",
    "    best_score = 0\n",
    "    best_model_state = None\n",
    "    best_i = 0\n",
    "    train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    for i, dec in enumerate(weight_decays):\n",
    "        model = HierarchicalRegressor().to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=dec)\n",
    "        total_loss = 0\n",
    "        non_increasing = 0\n",
    "        best_loss = None\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            for xb, yb in train_loader:\n",
    "                xb = xb.to(device)\n",
    "                yb = yb.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(xb)\n",
    "                loss = rmse_loss(logits, yb.to(dtype=torch.float32))\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            if best_loss is None or total_loss < best_loss:\n",
    "                non_increasing = 0\n",
    "                best_loss = total_loss\n",
    "            else:\n",
    "                if non_increasing == 4:\n",
    "                    break\n",
    "                non_increasing += 1\n",
    "            total_loss = 0\n",
    "\n",
    "        val_acc = accuracy_classification(x_val, y_val, model, device=device, batch_size=batch_size)\n",
    "\n",
    "        if val_acc > best_score or i == 0:\n",
    "            best_score = val_acc\n",
    "            best_i = i\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "        del model # save space if running locally\n",
    "        gc.collect()\n",
    "        if device == \"mps\":\n",
    "            torch.mps.empty_cache()\n",
    "        elif device == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    best_model = HierarchicalRegressor().to(device)\n",
    "    best_model.load_state_dict(best_model_state)\n",
    "\n",
    "    test_acc = accuracy_classification(x_test, y_test, best_model, device=device, batch_size=batch_size)\n",
    "    return best_model, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "877bf652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_pv(x_train_n, y_train_n, model: BayesianLastLayerModel):\n",
    "    model.fit_posterior(x_train_n, y_train_n)\n",
    "    return evaluate(x_test, y_test, rmse_loss, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0c2ffe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_var(T, model: BayesianLastLayerModel, x):\n",
    "    V_ast = model.V_ast\n",
    "    sigma2 = model.sigma2\n",
    "    covs = compute_pred_cov(sigma2, model.feature_extractor, x, V_ast)\n",
    "    return torch.sum(covs, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7c576d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "def find_data_variance_hyperparam(x_train_cur, y_train_cur, cnn_layer, post_mean_fn, post_cov_fn):\n",
    "  data_variances = [0.05, 0.02]\n",
    "  combinations = list(product(data_variances, repeat=y_train_cur.shape[-1]))\n",
    "  best_model = None\n",
    "  best_loss = None\n",
    "  for sigmas in combinations:\n",
    "    model_wrapper = BayesianLastLayerModel(post_mean_fn, post_cov_fn, cnn_layer, torch.Tensor(sigmas)).to(device=device)\n",
    "    model_wrapper.fit_posterior(x_train_cur, y_train_cur)\n",
    "    score = evaluate(x_val.to(device=device), y_val.to(device=device), rmse_loss, model_wrapper)\n",
    "    if best_loss is None or score < best_loss:\n",
    "      best_model = model_wrapper\n",
    "      best_loss = score\n",
    "  test_score = evaluate(x_test, y_test, rmse_loss, best_model)\n",
    "  return best_model, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b6f2b8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_once_local_pred_var(x_train_cur, y_train_cur, Xs, cnn_layer, post_mean_fn, post_cov_fn):\n",
    "  model, test_score = find_data_variance_hyperparam(x_train_cur, y_train_cur, cnn_layer, post_mean_fn, post_cov_fn)\n",
    "  acq_lambda = lambda x: compute_var(100, model, x)\n",
    "  acq_scores = call_batchwise(acq_lambda, Xs, batch_size=512, device=device)\n",
    "  x_new = acq_scores.topk(acquired_points).indices.numpy()\n",
    "  return test_score, x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "277d0fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train_full_local_pv(acq_name, Xs, ys, x_init_train, y_init_train, cnn_layer):\n",
    "    post_mean_fn = vi_acq_functions[acq_name][0]\n",
    "    post_cov_fn = vi_acq_functions[acq_name][1]\n",
    "    scores = []\n",
    "    x_train_cur = x_init_train.detach().clone()\n",
    "    y_train_cur = y_init_train.detach().clone()\n",
    "    for i in tqdm(range(acquisition_times)):\n",
    "        score, x_new = train_once_local_pred_var(x_train_cur, y_train_cur, Xs, cnn_layer, post_mean_fn, post_cov_fn)\n",
    "        x_new_t = torch.tensor(x_new, dtype=torch.long)\n",
    "        x_train_cur = torch.cat([x_train_cur, Xs[x_new_t.cpu()].to(device)], dim=0)\n",
    "        y_train_cur = torch.cat([y_train_cur, ys[x_new_t.cpu()].to(device)], dim=0)\n",
    "        mask = torch.ones(Xs.shape[0], dtype=torch.bool)\n",
    "        mask[x_new_t.cpu()] = False\n",
    "        Xs = Xs[mask]\n",
    "        ys = ys[mask]\n",
    "\n",
    "        scores.append(score)\n",
    "\n",
    "    model, final_score = find_data_variance_hyperparam(x_train_cur, y_train_cur, cnn_layer, post_mean_fn, post_cov_fn)\n",
    "    scores.append(final_score)\n",
    "    scores = torch.tensor(scores, dtype=torch.float32)\n",
    "\n",
    "    return scores, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c12b9430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def train_acquisition_local_pv(acq_name):\n",
    "    print(\"Start fitting model\")\n",
    "    if os.path.exists(\"./cnn_mod.keras\"):\n",
    "      cnn_mod = HierarchicalRegressor()\n",
    "      cnn_mod.load_state_dict(torch.load(\"./cnn_mod.pt\", weights_only=True))\n",
    "      cnn_mod = cnn_mod.to(device=device)\n",
    "    else:\n",
    "      cnn_mod, _ = find_best_decay_local_cnn(x_train_new, y_train_new)\n",
    "      torch.save(cnn_mod.state_dict(), \"./cnn_mod.pt\")\n",
    "    cnn_layer = cnn_mod.conv\n",
    "    print(\"Model fitted\")\n",
    "    scores = []\n",
    "    for i in range(3):\n",
    "      if os.path.exists(f\"./{i}{str(acq_name)}.npy\"):\n",
    "        score = np.load(f\"./{i}{str(acq_name)}.npy\")\n",
    "        print(len(score))\n",
    "      else:\n",
    "        score, model = train_full_local_pv(acq_name, X_p, y_p, x_train_new, y_train_new, cnn_layer)\n",
    "        np.save(f\"./{i}{str(acq_name)}.npy\", score.detach().cpu().numpy())\n",
    "        print(score)\n",
    "      scores.append(score)\n",
    "    meaned_scores = torch.mean(torch.Tensor(scores, device=device), dim=0)\n",
    "\n",
    "    return meaned_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d739559c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fitting model\n",
      "Model fitted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [01:14<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 8.85 GiB, other allocations: 3.55 MiB, max allowed: 9.07 GiB). Tried to allocate 390.62 MiB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[174]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m results_local_vi = {}\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m acq_fun \u001b[38;5;129;01min\u001b[39;00m vi_acq_functions:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m   res = \u001b[43mtrain_acquisition_local_pv\u001b[49m\u001b[43m(\u001b[49m\u001b[43macq_fun\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m   \u001b[38;5;28mprint\u001b[39m(res)\n\u001b[32m      5\u001b[39m   np.save(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m./\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(acq_fun)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_local.npy\u001b[39m\u001b[33m\"\u001b[39m, res.numpy())\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[166]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mtrain_acquisition_local_pv\u001b[39m\u001b[34m(acq_name)\u001b[39m\n\u001b[32m     17\u001b[39m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(score))\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m   score, model = \u001b[43mtrain_full_local_pv\u001b[49m\u001b[43m(\u001b[49m\u001b[43macq_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcnn_layer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m   np.save(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m./\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(acq_name)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.npy\u001b[39m\u001b[33m\"\u001b[39m, score.detach().cpu().numpy())\n\u001b[32m     21\u001b[39m   \u001b[38;5;28mprint\u001b[39m(score)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[165]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mtrain_full_local_pv\u001b[39m\u001b[34m(acq_name, Xs, ys, x_init_train, y_init_train, cnn_layer)\u001b[39m\n\u001b[32m      7\u001b[39m y_train_cur = y_init_train.detach().clone()\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(acquisition_times)):\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     score, x_new = \u001b[43mtrain_once_local_pred_var\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_cur\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_cur\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcnn_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost_mean_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost_cov_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     x_new_t = torch.tensor(x_new, dtype=torch.long)\n\u001b[32m     11\u001b[39m     x_train_cur = torch.cat([x_train_cur, Xs[x_new_t.cpu()].to(device)], dim=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[173]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mtrain_once_local_pred_var\u001b[39m\u001b[34m(x_train_cur, y_train_cur, Xs, cnn_layer, post_mean_fn, post_cov_fn)\u001b[39m\n\u001b[32m      2\u001b[39m model, test_score = find_data_variance_hyperparam(x_train_cur, y_train_cur, cnn_layer, post_mean_fn, post_cov_fn)\n\u001b[32m      3\u001b[39m acq_lambda = \u001b[38;5;28;01mlambda\u001b[39;00m x: compute_var(\u001b[32m100\u001b[39m, model, x)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m acq_scores = \u001b[43mcall_batchwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43macq_lambda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m x_new = acq_scores.topk(acquired_points).indices.numpy()\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m test_score, x_new\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Studium/UDL/UDL_Repo/util.py:17\u001b[39m, in \u001b[36mcall_batchwise\u001b[39m\u001b[34m(fn, x, batch_size, device)\u001b[39m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     15\u001b[39m         batch = batch.to(device)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     out = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     outputs.append(out)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(outputs, dim=\u001b[32m0\u001b[39m).to(device=device)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[173]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mtrain_once_local_pred_var.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_once_local_pred_var\u001b[39m(x_train_cur, y_train_cur, Xs, cnn_layer, post_mean_fn, post_cov_fn):\n\u001b[32m      2\u001b[39m   model, test_score = find_data_variance_hyperparam(x_train_cur, y_train_cur, cnn_layer, post_mean_fn, post_cov_fn)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m   acq_lambda = \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mcompute_var\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m   acq_scores = call_batchwise(acq_lambda, Xs, batch_size=\u001b[32m512\u001b[39m, device=device)\n\u001b[32m      5\u001b[39m   x_new = acq_scores.topk(acquired_points).indices.numpy()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[162]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mcompute_var\u001b[39m\u001b[34m(T, model, x)\u001b[39m\n\u001b[32m      2\u001b[39m V_ast = model.V_ast\n\u001b[32m      3\u001b[39m sigma2 = model.sigma2\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m covs = \u001b[43mcompute_pred_cov\u001b[49m\u001b[43m(\u001b[49m\u001b[43msigma2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mV_ast\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch.sum(covs, dim=-\u001b[32m1\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[149]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mcompute_pred_cov\u001b[39m\u001b[34m(sigma_2, model, x, blocks_of_cov_post)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_pred_cov\u001b[39m(sigma_2, model, x, blocks_of_cov_post):\n\u001b[32m      2\u001b[39m     model.eval()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     y_ast = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     V_pred = torch.einsum(\u001b[33m'\u001b[39m\u001b[33mbd,kde,be->kb\u001b[39m\u001b[33m'\u001b[39m, y_ast, blocks_of_cov_post, y_ast).T\n\u001b[32m      5\u001b[39m     idx = torch.arange(V_pred.shape[\u001b[32m0\u001b[39m] * sigma_2.shape[\u001b[32m0\u001b[39m], device=sigma_2.device) % sigma_2.shape[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Studium/UDL/UDL_Repo/venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Studium/UDL/UDL_Repo/venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Studium/UDL/UDL_Repo/venv/lib/python3.13/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Studium/UDL/UDL_Repo/venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Studium/UDL/UDL_Repo/venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Studium/UDL/UDL_Repo/venv/lib/python3.13/site-packages/torch/nn/modules/conv.py:548\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Studium/UDL/UDL_Repo/venv/lib/python3.13/site-packages/torch/nn/modules/conv.py:543\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    533\u001b[39m         F.pad(\n\u001b[32m    534\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    541\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    542\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: MPS backend out of memory (MPS allocated: 8.85 GiB, other allocations: 3.55 MiB, max allowed: 9.07 GiB). Tried to allocate 390.62 MiB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "results_local_vi = {}\n",
    "for acq_fun in vi_acq_functions:\n",
    "  res = train_acquisition_local_pv(acq_fun)\n",
    "  print(res)\n",
    "  np.save(f\"./{str(acq_fun)}_local.npy\", res.numpy())\n",
    "  results_local_vi[acq_fun] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45804ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = list(range(20, 20 + acquired_points * acquisition_times + 1, acquired_points))\n",
    "for key in results_local_vi:\n",
    "  plt.plot(steps, results_local_vi[key], label=key)\n",
    "plt.xlabel(\"Number of points\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.legend()\n",
    "plt.savefig(\"./vi_acq_plot.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec9549a",
   "metadata": {},
   "source": [
    "# Neural Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8385000",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NPModel(nn.Module):\n",
    "    def __init__(self, num_classes, moG=1):\n",
    "        super().__init__()\n",
    "        self.mog = moG\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.attn = nn.MultiheadAttention(\n",
    "            embed_dim=64,\n",
    "            num_heads=1,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.norm = nn.LayerNorm(64)\n",
    "\n",
    "        self.mean_head = nn.Sequential(\n",
    "            nn.Linear(64, num_classes * moG),\n",
    "        )\n",
    "\n",
    "        self.logvar_head = nn.Sequential(\n",
    "            nn.Linear(64, num_classes * moG),\n",
    "        )\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 4 and x.shape[-1] == 1:\n",
    "            x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        x = self.cnn(x)\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "\n",
    "        attn_out, _ = self.attn(x, x, x)\n",
    "        x = self.norm(x + attn_out)\n",
    "\n",
    "        mean = self.mean_head(x).view(-1, self.num_classes, self.mog)\n",
    "        logvar = self.logvar_head(x).view(-1, self.num_classes, self.mog)\n",
    "\n",
    "        return torch.stack([mean, logvar], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541b69e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NPInferenceModel(nn.Module):\n",
    "  def __init__(self, np_model: NPModel):\n",
    "    super().__init__()\n",
    "    self.np_model = np_model\n",
    "\n",
    "  def call(self, z, **kwargs):\n",
    "    mogs = self.np_model(z)\n",
    "    eps = torch.normal(torch.zeros((z.shape[0], mogs.shape[1], mogs.shape[2])), torch.ones((z.shape[0], mogs.shape[1], mogs.shape[2]))).to(device=device)\n",
    "    means = mogs[:, :, :, 0]\n",
    "    log_vars = mogs[:, :, :, 1]\n",
    "    return torch.sum(means + torch.sqrt(torch.exp(log_vars)) * eps, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eba3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_acquisition_fn(T, model, x):\n",
    "  model.eval()\n",
    "  mog = model(x)\n",
    "  return torch.sum(torch.sum(torch.exp(mog[:, :, :, 1]), dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02f9d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_batchwise_np_acq(model, x, batch_size=164):\n",
    "  return torch.concat([np_acquisition_fn(1, model, x[i:i+batch_size]) for i in range(0, x.shape[0], batch_size)], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc8faa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_np(model, x, y, batch_size=164):\n",
    "  y_hat = torch.concat([model(x[i:i+batch_size]) for i in range(0, x.shape[0], batch_size)], dim=0)\n",
    "  return rmse_loss(y, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd05ec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_decay_np(x_train, y_train, x_val, y_val):\n",
    "    weight_decays = [0, 1e-6, 5e-6, 1e-5, 1e-4]\n",
    "    best_score = 0\n",
    "    best_model_state = None\n",
    "    best_i = 0\n",
    "    train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    for i, dec in enumerate(weight_decays):\n",
    "\n",
    "        model = NPModel().to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=dec)\n",
    "        criterion = nll_logvar\n",
    "        total_loss = 0\n",
    "        non_increasing = 0\n",
    "        best_loss = None\n",
    "\n",
    "        for epoch in range(50):\n",
    "            model.train()\n",
    "            for xb, yb in train_loader:\n",
    "                xb = xb.to(device)\n",
    "                yb = yb.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(xb)\n",
    "                loss = criterion(logits, yb.to(dtype=logits.dtype))\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            if best_loss is None or total_loss < best_loss:\n",
    "                non_increasing = 0\n",
    "                best_loss = total_loss\n",
    "            else:\n",
    "                if non_increasing == 4:\n",
    "                    break\n",
    "                non_increasing += 1\n",
    "            total_loss = 0\n",
    "\n",
    "        inf_model = NPInferenceModel(model)\n",
    "        val_acc = accuracy_classification(x_val, y_val, inf_model, device=device, batch_size=batch_size)\n",
    "\n",
    "        if val_acc > best_score or i == 0:\n",
    "            best_score = val_acc\n",
    "            best_i = i\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "        del model # save space if running locally\n",
    "        gc.collect()\n",
    "        if device == \"mps\":\n",
    "            torch.mps.empty_cache()\n",
    "        elif device == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    best_model = NPModel().to(device)\n",
    "    best_model.load_state_dict(best_model_state)\n",
    "\n",
    "    test_acc = accuracy_classification(x_test, y_test, NPInferenceModel(best_model), device=device, batch_size=batch_size)\n",
    "    return best_model, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d1d677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def train_once_local_opt_np(x_train_cur, y_train_cur, Xs, ys, i):\n",
    "  if os.path.exists(f\"./model_artifacts/np_model_new_{i}.pt\"):\n",
    "    model_curr = NPModel(10)\n",
    "    model_curr.load_state_dict(torch.load(f\"./model_artifacts/np_model_new_{i}.pt\", weights_only=True))\n",
    "    model_curr.to(device=device)\n",
    "    test_score = evaluate_np(NPInferenceModel(model_curr), x_test, y_test)\n",
    "  else:\n",
    "    model_curr, test_score = find_best_decay_np(x_train_cur, y_train_cur, x_val, y_val)\n",
    "    torch.save(model_curr.state_dict(), f\"./model_artifacts/np_model_new_{i}.pt\")\n",
    "  acq_scores = call_batchwise_np_acq(model_curr, Xs, batch_size=512)\n",
    "  x_new = acq_scores.topk(acquired_points).indices\n",
    "  return test_score, x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07822248",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train_full_local_np(Xs, ys, x_init_train, y_init_train):\n",
    "  scores = []\n",
    "  x_train_cur = x_init_train.copy()\n",
    "  y_train_cur = y_init_train.copy()\n",
    "  for i in tqdm(range(acquisition_times)):\n",
    "    score, x_new = train_once_local_opt_np(x_train_cur, y_train_cur, Xs, ys, i)\n",
    "    x_new_t = torch.tensor(x_new, dtype=torch.long)\n",
    "    x_train_cur = torch.cat([x_train_cur, Xs[x_new_t.cpu()].to(device)], dim=0)\n",
    "    y_train_cur = torch.cat([y_train_cur, ys[x_new_t.cpu()].to(device)], dim=0)\n",
    "    mask = torch.ones(Xs.shape[0], dtype=torch.bool)\n",
    "    mask[x_new_t.cpu()] = False\n",
    "    Xs = Xs[mask]\n",
    "    ys = ys[mask]\n",
    "    scores.append(score)\n",
    "\n",
    "  model, score = find_best_decay_np(x_train_cur, y_train_cur, x_val, y_val)\n",
    "  scores.append(score)\n",
    "  return torch.stack(scores, dim=0), model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a607a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./model_artifacts\", exists_ok=True)\n",
    "def train_acquisition_np():\n",
    "  scores = []\n",
    "  for i in range(3):\n",
    "    score, model = train_full_local_np(X_p, y_p, x_train_new, y_train_new)\n",
    "    scores.append(score)\n",
    "    print(score)\n",
    "    np.save(f\"./{i}np_local.npy\", score.detach().cpu().numpy())\n",
    "  meaned_scores = torch.mean(torch.Tensor(scores), dim=0)\n",
    "\n",
    "  return meaned_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffc8253",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = train_acquisition_np()\n",
    "print(res)\n",
    "np.save(f\"./np_results.npy\", res.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f024b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.load('0np_local.npy')\n",
    "steps = list(range(20, 20 + acquired_points * acquisition_times + 1, acquired_points))\n",
    "plt.plot(steps, res, label=\"Neural Process\")\n",
    "plt.xlabel(\"Number of points\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.legend()\n",
    "plt.savefig(\"./np_acq_plot.svg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
