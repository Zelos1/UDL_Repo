{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zshkVT_Zb3u"
      },
      "source": [
        "# Preparing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQKBtcPkZCBl"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'venv (Python 3.13.9)' requires the ipykernel package.\n",
            "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/Users/hstumpf/Documents/Studium/UDL/UDL_Repo/venv/bin/python -m pip install ipykernel -U --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from load_data import load_mnist\n",
        "from util import *\n",
        "\n",
        "import time\n",
        "import math\n",
        "np.random.seed(43)\n",
        "\n",
        "x_train_new, y_train_new, X_p, y_p, x_val, y_val, x_test, y_test = load_mnist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NESBDl7NZSir"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "epochs = 30\n",
        "acquired_points = 10\n",
        "acquisition_times = 100\n",
        "device = torch.device(\"mps\") if torch.mps.is_available() else \"cpu\"\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else device\n",
        "x_train_new = x_train_new.to(device)\n",
        "y_train_new = y_train_new.to(device)\n",
        "x_val = x_val.to(device)\n",
        "y_val = y_val.to(device)\n",
        "x_test = x_test.to(device)\n",
        "y_test = y_test.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iw-nmiGGZgfA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=4), # -3 width/height\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, kernel_size=4), # -3 width/height\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2) # /2 width/height\n",
        "        )\n",
        "\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.fc1 = nn.Linear(32 * 11 * 11, 128)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        return F.softmax(x, dim=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0urxI3zZuFg"
      },
      "outputs": [],
      "source": [
        "from acq_functions import *\n",
        "\n",
        "acq_funs = {\n",
        "    \"max_entropy\": max_entropy,\n",
        "    \"bald\": bald,\n",
        "    \"var_ratios\": var_ratios,\n",
        "    \"mean_std\": mean_std,\n",
        "    \"random\": random\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sampling_steps = 5\n",
        "mc_sampling = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PV-isdY0axxf"
      },
      "source": [
        "# Train part local\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLoD8VvzZ5B7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import gc\n",
        "\n",
        "def find_best_decay_local(x_train, y_train):\n",
        "\n",
        "    weight_decays = [0, 1e-6, 5e-6, 1e-5, 1e-4]\n",
        "    best_score = 0\n",
        "    best_model_state = None\n",
        "    best_i = 0\n",
        "    train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=batch_size, shuffle=True\n",
        "    )\n",
        "\n",
        "    for i, dec in enumerate(weight_decays):\n",
        "\n",
        "        model = CNN().to(device)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=dec)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        total_loss = 0\n",
        "        non_increasing = 0\n",
        "        best_loss = None\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            for xb, yb in train_loader:\n",
        "                xb = xb.to(device)\n",
        "                yb = yb.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                logits = model(xb)\n",
        "\n",
        "                loss = criterion(logits, yb.to(dtype=torch.float32))\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "            if best_loss is None or total_loss < best_loss:\n",
        "                non_increasing = 0\n",
        "                best_loss = total_loss\n",
        "            else:\n",
        "                if non_increasing == 4:\n",
        "                    break\n",
        "                non_increasing += 1\n",
        "            total_loss = 0\n",
        "\n",
        "        val_acc = accuracy_classification(x_val, y_val, model, device=device, batch_size=batch_size)\n",
        "\n",
        "        if val_acc > best_score or i == 0:\n",
        "            best_score = val_acc\n",
        "            best_i = i\n",
        "            best_model_state = model.state_dict()\n",
        "\n",
        "        del model # save space if running locally\n",
        "        gc.collect()\n",
        "        if device == \"mps\":\n",
        "            torch.mps.empty_cache()\n",
        "        elif device == \"cuda\":\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    best_model = CNN().to(device)\n",
        "    best_model.load_state_dict(best_model_state)\n",
        "\n",
        "    test_acc = accuracy_classification(x_test, y_test, best_model, device=device, batch_size=batch_size)\n",
        "    return best_model, test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYJgAkacab92"
      },
      "outputs": [],
      "source": [
        "def train_once_local_opt(\n",
        "        x_train_cur, y_train_cur,\n",
        "        acquisition_fn,\n",
        "        Xs):\n",
        "\n",
        "    model_curr, test_score = find_best_decay_local(\n",
        "        x_train_cur, y_train_cur\n",
        "    )\n",
        "\n",
        "    acq_lambda = lambda x: acquisition_fn(100, model_curr, x)\n",
        "    acq_scores = call_batchwise(acq_lambda, Xs, batch_size=32, device=device)\n",
        "\n",
        "    del model_curr # save space if running locally\n",
        "    gc.collect()\n",
        "    if device == \"mps\":\n",
        "        torch.mps.empty_cache()\n",
        "    elif device == \"cuda\":\n",
        "        torch.cuda.empty_cache()\n",
        "    _, topk_idx = torch.topk(acq_scores, acquired_points)\n",
        "    return test_score, topk_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "st2OYiyKau6M"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "def train_full_local(acquisition_fn, Xs, ys, x_init_train, y_init_train):\n",
        "\n",
        "    scores = []\n",
        "\n",
        "    # Copies of initial training set as they are changed\n",
        "    x_train_cur = x_init_train.clone()\n",
        "    y_train_cur = y_init_train.clone()\n",
        "\n",
        "    for _ in tqdm(range(acquisition_times)):\n",
        "        score, x_new = train_once_local_opt(x_train_cur, y_train_cur, acquisition_fn, Xs)\n",
        "        x_new_t = torch.tensor(x_new, dtype=torch.long)\n",
        "        x_train_cur = torch.cat([x_train_cur, Xs[x_new_t.cpu()].to(device)], dim=0)\n",
        "        y_train_cur = torch.cat([y_train_cur, ys[x_new_t.cpu()].to(device)], dim=0)\n",
        "        mask = torch.ones(Xs.shape[0], dtype=torch.bool)\n",
        "        mask[x_new_t.cpu()] = False\n",
        "        Xs = Xs[mask]\n",
        "        ys = ys[mask]\n",
        "\n",
        "        scores.append(score)\n",
        "\n",
        "    model, final_score = find_best_decay_local(x_train_cur, y_train_cur)\n",
        "    scores.append(final_score)\n",
        "    scores = torch.tensor(scores, dtype=torch.float32)\n",
        "\n",
        "    return scores, model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYrO_bMXa9oi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def train_acquisition_local(acquisition_fn):\n",
        "    scores = []\n",
        "\n",
        "    for i in range(3):\n",
        "        score, model = train_full_local(acquisition_fn, X_p, y_p, x_train_new, y_train_new)\n",
        "        scores.append(score)\n",
        "        print(score)\n",
        "        np.save(f\"./{i}{str(acquisition_fn)}_local.npy\", score.cpu().numpy())\n",
        "\n",
        "    meaned_scores = torch.stack(scores, dim=0).mean(dim=0)\n",
        "    return meaned_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "s_GiFEhzbAid"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 57/100 [10:27:27<7:53:20, 660.48s/it]  \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m results_local = {}\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m acq_fun \u001b[38;5;129;01min\u001b[39;00m acq_funs:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m   res = \u001b[43mtrain_acquisition_local\u001b[49m\u001b[43m(\u001b[49m\u001b[43macq_funs\u001b[49m\u001b[43m[\u001b[49m\u001b[43macq_fun\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m   \u001b[38;5;28mprint\u001b[39m(res)\n\u001b[32m      5\u001b[39m   np.save(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m./\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(acq_fun)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_local.npy\u001b[39m\u001b[33m\"\u001b[39m, res.cpu().numpy())\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mtrain_acquisition_local\u001b[39m\u001b[34m(acquisition_fn)\u001b[39m\n\u001b[32m      5\u001b[39m scores = []\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m):   \u001b[38;5;66;03m# same range as your TF version\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     score, model = \u001b[43mtrain_full_local\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43macquisition_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx_train_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_new\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     scores.append(score)\n\u001b[32m     16\u001b[39m     \u001b[38;5;28mprint\u001b[39m(score)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mtrain_full_local\u001b[39m\u001b[34m(acquisition_fn, Xs, ys, x_init_train, y_init_train)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# ---------------------------------------------------------\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Main active learning loop\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# ---------------------------------------------------------\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(acquisition_times)):\n\u001b[32m     16\u001b[39m \n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m# Train a model and acquire new points\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     score, x_new = \u001b[43mtrain_once_local_opt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx_train_cur\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_cur\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43macquisition_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43mXs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# any other args handled inside train_once_local_opt\u001b[39;49;00m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     \u001b[38;5;66;03m# x_new is a numpy array of indices; convert to torch\u001b[39;00m\n\u001b[32m     26\u001b[39m     x_new_t = torch.tensor(x_new, dtype=torch.long)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mtrain_once_local_opt\u001b[39m\u001b[34m(x_train_cur, y_train_cur, acquisition_fn, Xs, ys)\u001b[39m\n\u001b[32m     16\u001b[39m acq_lambda = \u001b[38;5;28;01mlambda\u001b[39;00m x: acquisition_fn(\u001b[32m100\u001b[39m, model_curr, x)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# ---------------------------------\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Compute acquisition scores batchwise\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# ---------------------------------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m acq_scores = \u001b[43mcall_batchwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43macq_lambda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m model_curr\n\u001b[32m     25\u001b[39m gc.collect()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mcall_batchwise\u001b[39m\u001b[34m(fn, x, batch_size, device)\u001b[39m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     19\u001b[39m         batch = batch.to(device)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     out = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# fn should return a tensor\u001b[39;00m\n\u001b[32m     22\u001b[39m     outputs.append(out.cpu())  \u001b[38;5;66;03m# collect on CPU\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(outputs, dim=\u001b[32m0\u001b[39m).to(device=device)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mtrain_once_local_opt.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m      9\u001b[39m model_curr, test_score = find_best_decay_local(\n\u001b[32m     10\u001b[39m     x_train_cur, y_train_cur\n\u001b[32m     11\u001b[39m )\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# ---------------------------------\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Acquisition function lambda\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# ---------------------------------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m acq_lambda = \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43macquisition_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_curr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# ---------------------------------\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Compute acquisition scores batchwise\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# ---------------------------------\u001b[39;00m\n\u001b[32m     21\u001b[39m acq_scores = call_batchwise(acq_lambda, Xs)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mmax_entropy\u001b[39m\u001b[34m(T, model, x)\u001b[39m\n\u001b[32m     11\u001b[39m     xb = x.to(device)\n\u001b[32m     12\u001b[39m     logits = model(xb)              \u001b[38;5;66;03m# logits on device\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     probs = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# move to CPU\u001b[39;00m\n\u001b[32m     14\u001b[39m     probs_sum += probs\n\u001b[32m     15\u001b[39m mean_probs = probs_sum / \u001b[38;5;28mfloat\u001b[39m(T)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "results_local = {}\n",
        "for acq_fun in acq_funs:\n",
        "  res = train_acquisition_local(acq_funs[acq_fun])\n",
        "  print(res)\n",
        "  np.save(f\"./{str(acq_fun)}_local.npy\", res.cpu().numpy())\n",
        "  results_local[acq_fun] = res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "steps = list(range(20, 20 + acquired_points * acquisition_times + 1, acquired_points))\n",
        "for key in results_local:\n",
        "  plt.plot(steps, results_local[key], label=key)\n",
        "plt.grid()\n",
        "plt.xlabel(\"Number of points\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.savefig(\"./local_acq_plot.svg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deterministic Acquisition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def deterministic_max_entropy(T, model, x):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(x)\n",
        "        individual = outputs * torch.log(outputs + 1e-10)\n",
        "        return -torch.sum(individual, dim=-1)\n",
        "\n",
        "\n",
        "def deterministic_bald(T, model, x):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        me = deterministic_max_entropy(1, model, x)\n",
        "        outputs = model(x)\n",
        "        outputs = outputs * torch.log(outputs + 1e-10)\n",
        "        outputs = -torch.sum(outputs, dim=-1)\n",
        "\n",
        "        return me - outputs\n",
        "\n",
        "\n",
        "def deterministic_var_ratios(T, model, x):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(x)\n",
        "        return 1.0 - torch.max(outputs, dim=-1).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "acq_funs = {\"deterministic_max_entropy\": deterministic_max_entropy, \"deterministic_bald\": deterministic_bald, \"deterministic_var_ratios\": deterministic_var_ratios}\n",
        "results_local_det = {}\n",
        "for acq_fun in acq_funs:\n",
        "  res = train_acquisition_local(acq_funs[acq_fun])\n",
        "  print(res)\n",
        "  np.save(f\"./{str(acq_fun)}.npy\", res.numpy())\n",
        "  results_local_det[acq_fun] = res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "steps = list(range(20, 20 + acquired_points * acquisition_times + 1, acquired_points))\n",
        "for key in results_local_det:\n",
        "  plt.plot(steps, results_local_det[key], label=key)\n",
        "plt.xlabel(\"Number of points\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.savefig(\"./det_acq_plot.svg\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "9zshkVT_Zb3u"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
